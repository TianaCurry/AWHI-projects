{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using spaCy on annual report files \n",
    "- testing spaCy to do text analysis \n",
    "- starting with a single file, then write code to include all files from annual report google shared folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math as m \n",
    "import os \n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opening files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "AUTHOR-SUBJECT INDEX \n",
      "\n",
      "TO ARTICLES IN \n",
      "\n",
      "SMITHSONIAN ANNUAL REPORTS \n",
      "1849-1961 \n",
      "\n",
      "\n",
      "\n",
      "Compiled by \n",
      "\n",
      "RUTH M. STEMPLE \n",
      "\n",
      "Florida State University Library \n",
      "\n",
      "and \n",
      "\n",
      "THE EDITORIAL AND PUBLICATIONS DIVISION \n",
      "\n",
      "SMITHSONIAN INSTITUTION \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(Publication 4503) \n",
      "\n",
      "\n",
      "\n",
      "SMITHSONIAN INSTITUTION \n",
      "WASHINGTON 1 1963 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PREFACE \n",
      "\n",
      "The Smithsonian Institution was established in 1846 as the result of \n",
      "the bequest of James Smithson, an English scientist. He bequeathed \n",
      "his entire fortune to the United States of America for the purpose \n",
      "of founding \"an establishment for the increase and diffusion of \n",
      "knowledge among men.\" For the increase of knowledge, the Insti- \n",
      "tution is continuously engaged in research in many branches of science, \n",
      "as well as scientific expeditions to all parts of the world; the diffusion \n",
      "of knowledge is accomplished principally by the extensive exhibits \n",
      "in its museums, its art galleries, and its zoological park, and by several \n",
      "series of publications which are distributed throughout the w\n"
     ]
    }
   ],
   "source": [
    "#open/read a text file , no output \n",
    "annual_report_1963 = open(\"annualreporto18491961smit_djvu.txt\",\"r\")\n",
    "\n",
    "#prints entire file in output\n",
    "#[:0000] used to determine how many words to display \n",
    "print(annual_report_1963.read()[:1000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^I had issues with reading my text file \n",
    "- found my directory using os (import os) \n",
    "- next two steps helps you find your directory and files in your current directory\n",
    "- link: https://stackoverflow.com/questions/12201928/python-open-gives-ioerror-errno-2-no-such-file-or-directory\n",
    "- built-in functions in python: https://docs.python.org/3/library/functions.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AWHI_job_title_tidy_data_frame.csv',\n",
       " 'AWHI_cleaned_dataframe.csv',\n",
       " 'AWHI_testing_plotly_graphics_line_charts.ipynb',\n",
       " 'annualreporto18491961smit_djvu.txt',\n",
       " 'AWHI_install_spaCy.ipynb',\n",
       " '.gitignore',\n",
       " 'AWHI_spaCy_annual_reports.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " '.git',\n",
       " 'Install_plotly_testing_graphics_line_charts.ipynb',\n",
       " 'AWHI_job_titles_plotly_graphics.ipynb',\n",
       " 'job_titles_graph']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to list files in current working directory\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/curryt/Documents/GitHub/AWHI-projects'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check what directory you're in \n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Frequency \n",
    "\n",
    "- using methods and examples from soaCy for beginners - NLP\n",
    "- link: https://blog.ekbana.com/nlp-for-beninners-using-spacy-6161cf48a229\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Most', 1), ('outlay', 1), ('home', 1), ('No', 1), ('surprise', 1)]\n"
     ]
    }
   ],
   "source": [
    "#example from website \n",
    "#7. Get word frequnecy \n",
    "#testing to see if it runs \n",
    "\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"\"\"Most of the outlay will be at home. No surprise there, either. While Samsung has expanded overseas, South Korea is still host to most of its factories and research engineers.\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "#remove stopwors and punctuations\n",
    "\n",
    "words = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "\n",
    "word_freq = Counter(words)\n",
    "\n",
    "common_words = word_freq.most_common(5)\n",
    "\n",
    "print (common_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- link: https://spacy.io/api/token\n",
    "    - shows the use and extensions for different containers, pipelines and functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# most common word count using spaCy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common words by text function\n",
      "[('W.', 577), ('H.', 551), ('A.', 550), ('J.', 547), ('1', 451), ('E.', 416), ('F.', 355), ('S.', 339), ('M.', 329), ('C.', 315), ('R.', 305), ('G.', 304), ('L.', 263), ('William', 241), ('B.', 236), ('P.', 205), ('Charles', 204), (\"'s\", 200), ('19', 200), ('County', 195), ('T.', 192), ('America', 191), ('George', 176), ('Henry', 176), ('John', 173), ('3', 168), ('New', 162), ('1961', 159), ('D.', 153), ('Antiquities', 144), ('See', 138), ('James', 136), ('man', 134), ('North', 129), ('1903', 128), ('1904', 127), ('191', 124), ('Indians', 123), ('Indian', 121), ('life', 120), ('States', 118), ('2', 116), ('history', 115), ('1867', 114), ('earth', 113), ('Robert', 109), ('N.', 107), ('Jr.', 106), ('SMITHSONIAN', 105), ('United', 105)]\n",
      "Common words by norm function\n",
      "[('w.', 577), ('h.', 551), ('a.', 550), ('j.', 547), ('1', 451), ('e.', 416), ('f.', 355), ('s.', 339), ('m.', 329), ('c.', 315), ('r.', 305), ('g.', 304), ('l.', 263), ('william', 241), ('b.', 236), ('p.', 205), ('charles', 204), ('new', 204), (\"'s\", 200), ('19', 200), ('county', 195), ('history', 193), ('t.', 192), ('america', 191), ('henry', 179), ('george', 176), ('john', 173), ('3', 168), ('antiquities', 166), ('smithsonian', 162), ('ancient', 160), ('1961', 159), ('life', 153), ('d.', 153), ('man', 153), ('mounds', 150), ('institution', 146), ('earth', 143), ('progress', 141), ('recent', 138), ('north', 138), ('see', 138), ('james', 136), ('1903', 128), ('1904', 127), ('191', 124), ('indians', 123), ('states', 121), ('indian', 121), ('index', 117)]\n",
      "Common words by lemma function\n",
      "[('w.', 577), ('h.', 551), ('a.', 550), ('j.', 547), ('1', 451), ('e.', 416), ('f.', 355), ('s.', 339), ('m.', 329), ('c.', 315), ('r.', 305), ('g.', 304), ('l.', 263), ('william', 241), ('b.', 236), ('new', 206), ('p.', 205), ('charles', 204), ('19', 200), (\"'s\", 198), ('county', 195), ('history', 193), ('t.', 192), ('america', 191), ('henry', 179), ('george', 176), ('john', 173), ('report', 170), ('3', 168), ('ancient', 166), ('smithsonian', 162), ('man', 161), ('1961', 159), ('life', 154), ('d.', 153), ('institution', 149), ('antiquities', 145), ('earth', 143), ('progress', 141), ('relation', 141), ('see', 141), ('recent', 138), ('north', 138), ('james', 136), ('plant', 133), ('1903', 128), ('science', 127), ('1904', 127), ('191', 124), ('indians', 123)]\n"
     ]
    }
   ],
   "source": [
    "#example from website\n",
    "\n",
    "#need to test with a file saved on your own computer, so the information in open() will change\n",
    "#this information will be different for each computer in open()\n",
    "\n",
    "#open the file you want to do word fequency\n",
    "#with open function will close files once the function is done running\n",
    "#directory is imported from github in the same directory so no need to include /Desktop/User\n",
    "with open(\"annualreporto18491961smit_djvu.txt\",\"r\") as annual_report_1963:\n",
    "\n",
    "    #need to add \".read()\" so that it will look at the text in the open file\n",
    "    doc = nlp(annual_report_1963.read())\n",
    "\n",
    "#testing the results of \n",
    "#results using text ext. funciton\n",
    "#useful to make words token to cut white space len(), stop code token.is_stop , and punction token.is_punct \n",
    "words_text = [token.text for token in doc if token.is_stop != True and token.is_punct != True and len(token.text.strip()) > 0]\n",
    "\n",
    "word_text_freq = Counter(words_text)\n",
    "\n",
    "common_words_text = word_text_freq.most_common(50)\n",
    "print(\"Common words by text function\")\n",
    "print(common_words_text)\n",
    "\n",
    "#results using norm_ ext. function\n",
    "#grouping variation of words i.e (dog, DOG,Dog, dogs, dog's)\n",
    "#everything is searchable by lowercase\n",
    "words_norm = [token.norm_ for token in doc if token.is_stop != True and token.is_punct != True and len(token.text.strip()) > 0]\n",
    "\n",
    "word_norm_freq = Counter(words_norm)\n",
    "\n",
    "common_words_norm = word_norm_freq.most_common(50)\n",
    "print(\"Common words by norm function\")\n",
    "print(common_words_norm)\n",
    "\n",
    "#results using lemma_ ext. function \n",
    "#grouping variation of words and tense on verbs i.e (see, saw, seen), (dog, DOG,Dog, dogs, dog's)\n",
    "#everything is searchable by lowercase \n",
    "words_lemma = [token.lemma_ for token in doc if token.is_stop != True and token.is_punct != True and len(token.text.strip()) > 0]\n",
    "\n",
    "word_lemma_freq = Counter(words_lemma)\n",
    "\n",
    "common_words_lemma = word_lemma_freq.most_common(50)\n",
    "print(\"Common words by lemma function\")\n",
    "print(common_words_lemma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word count specific word given using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imput word you want to count, not counted with spacy token so doesn't count variations\n",
    "#only counts words like \"Smithsonian\" as it's typed\n",
    "#input which word to count using text word \n",
    "word_freq['Smithsonian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lemma_freq['smithsonian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_norm_freq['smithsonian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ websites reference: https://github.com/explosion/spaCy/issues/1851\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word count using io and spaCy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to do the same thing in a different way\n",
    "#this is an older way of writing this code\n",
    "#example with io\n",
    "\n",
    "import io\n",
    "\n",
    "ff = io.open(\"annualreporto18491961smit_djvu.txt\",\"r\", encoding='utf-8')\n",
    "doc = nlp(ff.read())\n",
    "words = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "\n",
    "word_freq = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = word_freq.most_common(5)\n",
    "\n",
    "print (common_words)\n",
    "\n",
    "ff.close()\n",
    "\n",
    "#this gives the same results as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ websites reference: https://github.com/explosion/spaCy/issues/1851"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing word counts without installed package  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word count with no packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count for \"Smithsonian\" annual report 1963\n",
    "counts = 0\n",
    "with open (\"annualreporto18491961smit_djvu.txt\") as openfile:\n",
    "    for line in openfile:\n",
    "        if \"Smithsonian\" in line:\n",
    "        #for part in line.split():\n",
    "            #if \"Smithsonian\" in part: \n",
    "            counts += 1 \n",
    "           # print(line)\n",
    "        if \"SMITHSONIAN\" in line:\n",
    "            counts += 1\n",
    "    #else:\n",
    "        #print(\"not found\")\n",
    "    print(\"word count = \",counts)\n",
    "# I need to write code so that Smithsonian and SMITHSONIAN and smithsonian match    \n",
    "              \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^website reference: https://stackoverflow.com/questions/38101704/how-to-count-items-boolean-after-if-statements-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening multiple files and counting words \n",
    "## code will not run properly, missing inputs\n",
    "- website reference:https://stackoverflow.com/questions/16997165/unique-word-frequency-in-multiple-files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will not run properly without change input, just a sample from a website\n",
    "from collections import Counter\n",
    "from glob import iglob\n",
    "import re\n",
    "import os\n",
    "\n",
    "def remove_garbage(text):\n",
    "    \"\"\"Replace non-word (non-alphanumeric) chars in text with spaces,\n",
    "       then convert and return a lowercase version of the result.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "topwords = 100\n",
    "folderpath = 'path/to/directory'\n",
    "counter = Counter()\n",
    "for filepath in iglob(os.path.join(folderpath, '*.txt')):\n",
    "    with open(filepath) as file:\n",
    "        counter.update(remove_garbage(file.read()).split())\n",
    "\n",
    "for word, count in counter.most_common(topwords):\n",
    "    print('{}: {}'.format(count, word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# web searches \n",
    "- libraries in python: https://www.edureka.co/blog/python-libraries/\n",
    "- best NLP libraries for python: https://elitedatascience.com/python-nlp-libraries\n",
    "- def functions: https://www.codementor.io/kaushikpal/user-defined-functions-in-python-8s7wyc8k2\n",
    "- opening multiple files using context manager: https://stackoverflow.com/questions/21680473/how-can-i-open-multiple-files-number-of-files-unknown-beforehand-using-with-o\n",
    "- counting word frequency with python: https://programminghistorian.org/en/lessons/counting-frequencies\n",
    "- functions in spacy: https://spacy.io/api/top-level\n",
    "- using spacy examples: https://www.analyticsvidhya.com/blog/2017/04/natural-language-processing-made-easy-using-spacy-%E2%80%8Bin-python/\n",
    "- using unicodedata: https://github.com/LightTable/Python/issues/24\n",
    "- text classifications in spacy: https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/\n",
    "- read,open,write,add to files: https://www.geeksforgeeks.org/reading-writing-text-files-python/\n",
    "- using io: https://github.com/explosion/spaCy/issues/1851\n",
    "- using io: https://stackoverflow.com/questions/37530891/python-pandas-nameerror-stringio-is-not-defined\n",
    "- how to count/ boolean: https://stackoverflow.com/questions/38101704/how-to-count-items-boolean-after-if-statements-python\n",
    "- opening files: https://codereview.stackexchange.com/questions/31395/python-open-multiple-files\n",
    "- opening files: https://stackoverflow.com/questions/38991923/how-to-open-multiple-files-in-a-directory/38992988\n",
    "- using countermanager: https://stackoverflow.com/questions/21680473/how-can-i-open-multiple-files-number-of-files-unknown-beforehand-using-with-o\n",
    "- what is contextlib: https://docs.python.org/3/library/contextlib.html\n",
    "- word frequency with multiple files: https://stackoverflow.com/questions/16997165/unique-word-frequency-in-multiple-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
